{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a12d1cf4",
   "metadata": {},
   "source": [
    "# **Week 2: Regressor**\n",
    "\n",
    "### **TAs: Chiku Parida (chipa@dtu.dk), Dr. Dipendu Roy (dipro@dtu.dk)**\n",
    "\n",
    "## **Objectives:**\n",
    "- Understand the concept of regression analysis.\n",
    "- Implement a simple linear regression model using Python.\n",
    "- Evaluate the performance of the regression model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861b8562",
   "metadata": {},
   "source": [
    "### Load the Dataset\n",
    "\n",
    "- The dataset is a CSV file containing chemicals and their associated features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa4fcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"data_regression.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbdbd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head())\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd79173",
   "metadata": {},
   "source": [
    "### Based on the simple description above, lets look into the feature columns and the target column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be46bc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "numerical_cols = df.select_dtypes(include=['number']).columns.tolist()\n",
    "\n",
    "print(\"Categorical columns:\", categorical_cols)\n",
    "print(\"Numerical columns:\", numerical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b028f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categorical_cols:\n",
    "    print(f\"Column: {col}\")\n",
    "    print(df[col].unique())\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f64d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categorical_cols:\n",
    "    n_unique = df[col].nunique(dropna=False)  \n",
    "    print(f\"{col}: {n_unique} unique values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4816fdd",
   "metadata": {},
   "source": [
    "## Preliminary data exploration and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2d00c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "df['structure'].value_counts().plot.pie(autopct='%1.1f%%', startangle=90)\n",
    "plt.title('Value Distribution in structure')\n",
    "plt.ylabel('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf914668",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "df['category'].value_counts().plot.pie(autopct='%1.1f%%', startangle=90)\n",
    "plt.title('Value Distribution in category')\n",
    "plt.ylabel('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f719d2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "value_counts = df['category'].value_counts()\n",
    "\n",
    "colors = sns.color_palette('Set2', len(value_counts))\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "bars = plt.bar(value_counts.index, value_counts.values, color=colors, edgecolor='black', width=0.6)\n",
    "\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, yval + value_counts.max() * 0.02,\n",
    "             f'{int(yval)}', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "# Styling\n",
    "plt.title('Value Distribution in Category', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Category', fontsize=12)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.xticks(rotation=90, fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.ylim(0, value_counts.max() * 1.15)  \n",
    "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ba1702",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df, x='category', y='log_breakdown_field')\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Breakdown Field by Material Category')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea62299e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot(df['log_breakdown_field'], kde=True)\n",
    "plt.xlabel(\"Log(Dielectric Breakdown Field)\")\n",
    "plt.title(\"Distribution of Target Variable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5673d1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = ['experimental_band_gap', 'phonon_cutoff_frequency', 'mean_phonon_frequency',\n",
    "                  'electronic_contribution_of_dielectric_constant', 'total_dielectric_constant',\n",
    "                  'nearest_neighbor_distance', 'density', 'bulk_modulus', 'log_breakdown_field']\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(df[numerical_cols].corr(), annot=True, fmt=\".2f\", cmap=\"coolwarm\")\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cebbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('category')[numerical_cols].mean().style.background_gradient(cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e304dca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "for cat in df['category'].unique():\n",
    "    sns.kdeplot(df[df['category'] == cat]['log_breakdown_field'], label=cat, fill=True)\n",
    "plt.title(\"Density of log_breakdown_field by Category\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc85cd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df['structure'] = LabelEncoder().fit_transform(df['structure'])\n",
    "df['category'] = LabelEncoder().fit_transform(df['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f9ccbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop(columns=['name', 'log_breakdown_field'])  \n",
    "y = df['log_breakdown_field']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f050de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Train a regressor\n",
    "reg = RandomForestRegressor(random_state=42)\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f\"R2 score: {r2:.3f}\")\n",
    "print(f\"RMSE: {rmse:.3f}\")\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.scatter(y_test, y_pred, color='dodgerblue', edgecolor='k', s=70)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "plt.xlabel(\"True log_breakdown_field\")\n",
    "plt.ylabel(\"Predicted log_breakdown_field\")\n",
    "plt.title(\"Random Forest Regression Results\")\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254ef45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Train a regressor\n",
    "reg = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42)\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f\"R2 score: {r2:.3f}\")\n",
    "print(f\"RMSE: {rmse:.3f}\")\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.scatter(y_test, y_pred, color='dodgerblue', edgecolor='k', s=70)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "plt.xlabel(\"True log_breakdown_field\")\n",
    "plt.ylabel(\"Predicted log_breakdown_field\")\n",
    "plt.title(\"Random Forest Regression Results\")\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97ad045",
   "metadata": {},
   "source": [
    "## Questions:\n",
    "\n",
    "1. **Which hyperparameters of `RandomForestRegressor` are most critical to tune for improved regression performance?**\n",
    "    - Refer to the [RandomForestRegressor documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html)\n",
    "\n",
    "2. **How can we systematically search for the best hyperparameter values?**\n",
    "    - Should we use grid search, random search?\n",
    "\n",
    "3. **What metric(s) should be used to evaluate model performance during hyperparameter tuning?**\n",
    "    - Is RMSE, R², or another metric most appropriate for this task?\n",
    "\n",
    "4. **How do we avoid overfitting while tuning hyperparameters?**\n",
    "    - Should we use cross-validation, and if so, what kind (e.g., k-fold)?\n",
    "\n",
    "5. **What ranges or values should be considered for each hyperparameter?**\n",
    "    - e.g. \"n_estimators\", \"max_depth\"\n",
    "\n",
    "6. **How does changing each hyperparameter affect model interpretability and computational cost?**\n",
    "    - Are there trade-offs between accuracy and training time?\n",
    "\n",
    "7. **Should feature selection or engineering be performed before hyperparameter tuning?**\n",
    "    - How might this impact the results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afc375a",
   "metadata": {},
   "source": [
    "## Now its time try some other regressors we studied during the morning session.\n",
    "\n",
    "1. [Linear Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)\n",
    "2. [Decision Tree Regressor](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html)\n",
    "3. [Gradient Boosting Regressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html)\n",
    "4. [XGBoost Regressor](https://xgboost.readthedocs.io/en/latest/python/python_api.html#xgboost.XGBRegressor)\n",
    "5. [AdaBoost Regressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostRegressor.html)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cp3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
